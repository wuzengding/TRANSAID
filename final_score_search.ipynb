{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b75049-7ff0-4463-a507-93a548e22534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation and Statistics:\n",
      "==================================================\n",
      "\n",
      "1. 原始数据统计:\n",
      "总行数: 18200\n",
      "包含NM_的行数: 13493\n",
      "包含NR_的行数: 4704\n",
      "\n",
      "2. 唯一转录本统计:\n",
      "唯一NM_转录本数: 13415\n",
      "唯一NR_转录本数: 4616\n",
      "\n",
      "3. 缺失值统计:\n",
      "transcript_id        0\n",
      "tis_position      3515\n",
      "tts_position      3515\n",
      "tis_sequence      3515\n",
      "tts_sequence      3515\n",
      "tis_prob_score    3515\n",
      "tts_prob_score    3515\n",
      "kozak_score       3515\n",
      "cai_score         3515\n",
      "gc_score          3515\n",
      "cds_length        3515\n",
      "final_score       3515\n",
      "filter_status        0\n",
      "true_tis          4867\n",
      "true_tts          4867\n",
      "dtype: int64\n",
      "\n",
      "4. final_score分布:\n",
      "count                  14685\n",
      "unique                 14645\n",
      "top       0.1433264726397471\n",
      "freq                       4\n",
      "Name: final_score, dtype: object\n",
      "\n",
      "5. 每个转录本的预测数量分布:\n",
      "1    17867\n",
      "2      162\n",
      "3        3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing NaN values:\n",
      "Total transcripts with all NaN scores: 3516\n",
      "NM transcripts: 163\n",
      "NR transcripts: 3352\n",
      "\n",
      "Transcript Level Results:\n",
      "==================================================\n",
      "Best Threshold: 0.520\n",
      "Accuracy: 0.917\n",
      "Precision: 0.923\n",
      "Recall: 0.967\n",
      "F1 Score: 0.944\n",
      "\n",
      "Detailed Counts:\n",
      "True Positives: 12711\n",
      "False Positives: 1065\n",
      "True Negatives: 3827\n",
      "False Negatives: 429\n",
      "Constant True Negatives: 0\n",
      "Constant False Negatives: 0\n",
      "\n",
      "Transcripts with Multiple Predictions: 63\n",
      "\n",
      "ORF Level Results:\n",
      "==================================================\n",
      "Best Threshold: 0.520\n",
      "Accuracy: 0.913\n",
      "Precision: 0.920\n",
      "Recall: 0.964\n",
      "F1 Score: 0.941\n",
      "\n",
      "Detailed Counts:\n",
      "True Positives: 12735\n",
      "False Positives: 1104\n",
      "True Negatives: 3881\n",
      "False Negatives: 480\n",
      "Constant True Negatives: 0\n",
      "Constant False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    \"\"\"性能指标数据类\"\"\"\n",
    "    threshold: float\n",
    "    tp: int  # 真阳性\n",
    "    fp: int  # 假阳性\n",
    "    tn: int  # 真阴性\n",
    "    fn: int  # 假阴性\n",
    "    multi_pred_count: int  # 多预测计数\n",
    "    constant_tn: int  # 恒定真阴性\n",
    "    constant_fn: int  # 恒定假阴性\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        \"\"\"计算准确率\"\"\"\n",
    "        total = self.tp + self.fp + self.tn + self.fn + self.constant_tn + self.constant_fn\n",
    "        return (self.tp + self.tn + self.constant_tn) / total if total > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def precision(self) -> float:\n",
    "        \"\"\"计算精确率\"\"\"\n",
    "        denominator = self.tp + self.fp\n",
    "        return self.tp / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def recall(self) -> float:\n",
    "        \"\"\"计算召回率\"\"\"\n",
    "        denominator = self.tp + self.fn + self.constant_fn\n",
    "        return self.tp / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def specificity(self) -> float:\n",
    "        \"\"\"计算特异性\"\"\"\n",
    "        denominator = self.tn + self.fp + self.constant_tn\n",
    "        return (self.tn + self.constant_tn) / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def fpr(self) -> float:\n",
    "        \"\"\"计算假阳性率\"\"\"\n",
    "        return 1 - self.specificity\n",
    "    \n",
    "    @property\n",
    "    def f1_score(self) -> float:\n",
    "        \"\"\"计算F1分数\"\"\"\n",
    "        prec = self.precision\n",
    "        rec = self.recall\n",
    "        denominator = prec + rec\n",
    "        return 2 * (prec * rec) / denominator if denominator > 0 else 0\n",
    "\n",
    "class ThresholdOptimizer:\n",
    "    \"\"\"阈值优化分析器\"\"\"\n",
    "    \n",
    "    def __init__(self, data_file: str, output_dir: str):\n",
    "        \"\"\"初始化优化器\"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 读取数据\n",
    "        self.df = pd.read_csv(os.path.join(output_dir, data_file))\n",
    "        \n",
    "        # 数据验证和统计\n",
    "        self._validate_and_print_stats()\n",
    "        \n",
    "        # 处理final_score\n",
    "        self._process_final_scores()\n",
    "        \n",
    "        # 按transcript_id分组\n",
    "        self.grouped_predictions = self.df.groupby('transcript_id')\n",
    "    def _validate_and_print_stats(self):\n",
    "        \"\"\"验证数据并打印统计信息\"\"\"\n",
    "        print(\"\\nData Validation and Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 原始转录本统计\n",
    "        nm_transcripts = self.df['transcript_id'].str.startswith('NM_')\n",
    "        nr_transcripts = self.df['transcript_id'].str.startswith('NR_')\n",
    "        \n",
    "        print(\"\\n1. 原始数据统计:\")\n",
    "        print(f\"总行数: {len(self.df)}\")\n",
    "        print(f\"包含NM_的行数: {nm_transcripts.sum()}\")\n",
    "        print(f\"包含NR_的行数: {nr_transcripts.sum()}\")\n",
    "        \n",
    "        # 唯一转录本统计\n",
    "        unique_nm = self.df[nm_transcripts]['transcript_id'].nunique()\n",
    "        unique_nr = self.df[nr_transcripts]['transcript_id'].nunique()\n",
    "        \n",
    "        print(\"\\n2. 唯一转录本统计:\")\n",
    "        print(f\"唯一NM_转录本数: {unique_nm}\")\n",
    "        print(f\"唯一NR_转录本数: {unique_nr}\")\n",
    "        \n",
    "        # 缺失值统计\n",
    "        print(\"\\n3. 缺失值统计:\")\n",
    "        print(self.df.isnull().sum())\n",
    "        \n",
    "        # final_score分布\n",
    "        print(\"\\n4. final_score分布:\")\n",
    "        print(self.df['final_score'].describe())\n",
    "        \n",
    "        # 每个转录本的预测数量\n",
    "        duplicates = self.df.groupby('transcript_id').size()\n",
    "        print(\"\\n5. 每个转录本的预测数量分布:\")\n",
    "        print(duplicates.value_counts().sort_index())\n",
    "\n",
    "    def _process_final_scores(self):\n",
    "        \"\"\"处理final_score，包括NaN值处理\"\"\"\n",
    "        # 转换为数值类型\n",
    "        self.df['final_score'] = pd.to_numeric(self.df['final_score'], errors='coerce')\n",
    "        \n",
    "        # 统计NaN值分布\n",
    "        nan_transcripts = self.df.groupby('transcript_id')['final_score'].apply(\n",
    "            lambda x: x.isna().all())\n",
    "        nan_transcripts = nan_transcripts[nan_transcripts]\n",
    "        \n",
    "        print(\"\\nProcessing NaN values:\")\n",
    "        print(f\"Total transcripts with all NaN scores: {len(nan_transcripts)}\")\n",
    "        print(f\"NM transcripts: {sum(i.startswith('NM_') for i in nan_transcripts.index)}\")\n",
    "        print(f\"NR transcripts: {sum(i.startswith('NR_') for i in nan_transcripts.index)}\")\n",
    "        \n",
    "        # 为NaN值分配随机值\n",
    "        np.random.seed(42)\n",
    "        for transcript_id in nan_transcripts.index:\n",
    "            random_score = np.random.uniform(0, 0.1)\n",
    "            self.df.loc[self.df['transcript_id'] == transcript_id, 'final_score'] = random_score\n",
    "\n",
    "    def _is_correct_prediction(self, row) -> bool:\n",
    "        \"\"\"判断单个预测是否正确\"\"\"\n",
    "        return (pd.notna(row['true_tis']) and \n",
    "                pd.notna(row['true_tts']) and \n",
    "                row['tis_position'] == row['true_tis'] and \n",
    "                row['tts_position'] == row['true_tts'])\n",
    "\n",
    "    def calculate_rates(self, metrics: PerformanceMetrics) -> Tuple[float, float]:\n",
    "        \"\"\"计算TPR和FPR，包含恒定值\"\"\"\n",
    "        tpr = metrics.tp / (metrics.tp + metrics.fn + metrics.constant_fn)\n",
    "        fpr = metrics.fp / (metrics.fp + metrics.tn + metrics.constant_tn)\n",
    "        return fpr, tpr\n",
    "\n",
    "    def evaluate_transcript_level(self, threshold: float) -> PerformanceMetrics:\n",
    "        \"\"\"转录本层面的评估\"\"\"\n",
    "        tp = fp = tn = fn = constant_tn = constant_fn = 0\n",
    "        multi_pred_count = 0\n",
    "        processed_transcripts = set()\n",
    "        \n",
    "        # 首先处理全是NaN的转录本\n",
    "        nan_transcripts = self.df.groupby('transcript_id')['final_score'].apply(\n",
    "            lambda x: x.isna().all())\n",
    "        \n",
    "        for transcript_id, is_all_nan in nan_transcripts.items():\n",
    "            if is_all_nan:\n",
    "                if transcript_id.startswith('NM_'):\n",
    "                    constant_fn += 1\n",
    "                else:\n",
    "                    constant_tn += 1\n",
    "                processed_transcripts.add(transcript_id)\n",
    "        \n",
    "        # 处理其他转录本\n",
    "        for transcript_id, group in self.grouped_predictions:\n",
    "            if transcript_id in processed_transcripts:\n",
    "                continue\n",
    "                \n",
    "            is_nm = transcript_id.startswith('NM_')\n",
    "            valid_predictions = group[\n",
    "                pd.notna(group['final_score']) & \n",
    "                (group['final_score'] > threshold)\n",
    "            ]\n",
    "            \n",
    "            if len(valid_predictions) > 1:\n",
    "                multi_pred_count += 1\n",
    "            \n",
    "            if is_nm:\n",
    "                if len(valid_predictions) == 0:\n",
    "                    fn += 1\n",
    "                elif len(valid_predictions) == 1:\n",
    "                    if self._is_correct_prediction(valid_predictions.iloc[0]):\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                if len(valid_predictions) > 0:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "        \n",
    "        return PerformanceMetrics(\n",
    "            threshold=threshold,\n",
    "            tp=tp,\n",
    "            fp=fp,\n",
    "            tn=tn,\n",
    "            fn=fn,\n",
    "            multi_pred_count=multi_pred_count,\n",
    "            constant_tn=constant_tn,\n",
    "            constant_fn=constant_fn\n",
    "        )\n",
    "        \n",
    "    def evaluate_orf_level(self, threshold: float) -> PerformanceMetrics:\n",
    "        \"\"\"ORF层面的评估\"\"\"\n",
    "        tp = fp = tn = fn = constant_tn = constant_fn = 0\n",
    "        multi_pred_count = 0\n",
    "        processed_transcripts = set()\n",
    "        \n",
    "        # 首先处理全是NaN的转录本\n",
    "        nan_transcripts = self.df.groupby('transcript_id')['final_score'].apply(\n",
    "            lambda x: x.isna().all())\n",
    "        \n",
    "        for transcript_id, is_all_nan in nan_transcripts.items():\n",
    "            if is_all_nan:\n",
    "                if transcript_id.startswith('NM_'):\n",
    "                    constant_fn += 1\n",
    "                else:\n",
    "                    constant_tn += 1\n",
    "                processed_transcripts.add(transcript_id)\n",
    "        \n",
    "        # 处理每个ORF预测\n",
    "        for _, row in self.df.iterrows():\n",
    "            if row['transcript_id'] in processed_transcripts:\n",
    "                continue\n",
    "                \n",
    "            is_nm = row['transcript_id'].startswith('NM_')\n",
    "            \n",
    "            if pd.isna(row['final_score']):\n",
    "                continue\n",
    "                \n",
    "            if row['final_score'] > threshold:\n",
    "                if is_nm and self._is_correct_prediction(row):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                if is_nm:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "        \n",
    "        return PerformanceMetrics(\n",
    "            threshold=threshold,\n",
    "            tp=tp,\n",
    "            fp=fp,\n",
    "            tn=tn,\n",
    "            fn=fn,\n",
    "            multi_pred_count=multi_pred_count,\n",
    "            constant_tn=constant_tn,\n",
    "            constant_fn=constant_fn\n",
    "        )\n",
    "\n",
    "    def _plot_dual_roc_curves(self, transcript_results: List[PerformanceMetrics], \n",
    "                           orf_results: List[PerformanceMetrics]):\n",
    "        \"\"\"绘制双ROC曲线\"\"\"\n",
    "        plt.figure(figsize=(4, 3), dpi=600)\n",
    "        \n",
    "        # 计算转录本层面ROC\n",
    "        fpr_t = []\n",
    "        tpr_t = []\n",
    "        for metrics in transcript_results:\n",
    "            fpr, tpr = self.calculate_rates(metrics)\n",
    "            fpr_t.append(fpr)\n",
    "            tpr_t.append(tpr)\n",
    "        auc_t = np.trapz(tpr_t, fpr_t)\n",
    "        \n",
    "        # 计算ORF层面ROC\n",
    "        fpr_o = []\n",
    "        tpr_o = []\n",
    "        for metrics in orf_results:\n",
    "            fpr, tpr = self.calculate_rates(metrics)\n",
    "            fpr_o.append(fpr)\n",
    "            tpr_o.append(tpr)\n",
    "        auc_o = np.trapz(tpr_o, fpr_o)\n",
    "        \n",
    "        # 绘制曲线\n",
    "        plt.plot(fpr_t, tpr_t, 'b-', label=f'Transcript Level (AUC={auc_t:.3f})')\n",
    "        plt.plot(fpr_o, tpr_o, 'r-', label=f'ORF Level (AUC={auc_o:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves: Transcript vs ORF Level')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True,lw=0.5)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'dual_roc_curves.png'), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_performance_curves(self, results: List[PerformanceMetrics], level: str):\n",
    "        \"\"\"绘制性能曲线\"\"\"\n",
    "        thresholds = [r.threshold for r in results]\n",
    "        metrics = {\n",
    "            'Accuracy': [r.accuracy for r in results],\n",
    "            'Precision': [r.precision for r in results],\n",
    "            'Recall': [r.recall for r in results],\n",
    "            'F1 Score': [r.f1_score for r in results]\n",
    "        }\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for metric_name, values in metrics.items():\n",
    "            plt.plot(thresholds, values, label=metric_name)\n",
    "        \n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'{level.capitalize()} Level Performance Metrics')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(self.output_dir, f'{level}_performance_curves.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_transcript_scores(self, results: List[PerformanceMetrics]):\n",
    "        \"\"\"绘制转录本得分分布\"\"\"\n",
    "        best_threshold = max(results, key=lambda x: x.f1_score).threshold\n",
    "        \n",
    "        transcript_data = {\n",
    "            'NM': {'correct': [], 'incorrect': []},\n",
    "            'NR': {'correct': [], 'incorrect': []}\n",
    "        }\n",
    "        \n",
    "        for transcript_id, group in self.grouped_predictions:\n",
    "            max_score = group['final_score'].max()\n",
    "            is_nm = transcript_id.startswith('NM_')\n",
    "            \n",
    "            if is_nm:\n",
    "                has_match = False\n",
    "                if max_score > best_threshold:\n",
    "                    for _, row in group.iterrows():\n",
    "                        if self._is_correct_prediction(row):\n",
    "                            has_match = True\n",
    "                            break\n",
    "                    if has_match:\n",
    "                        transcript_data['NM']['correct'].append(max_score)\n",
    "                    else:\n",
    "                        transcript_data['NM']['incorrect'].append(max_score)\n",
    "                else:\n",
    "                    transcript_data['NM']['incorrect'].append(max_score)\n",
    "            else:\n",
    "                if max_score > best_threshold:\n",
    "                    transcript_data['NR']['incorrect'].append(max_score)\n",
    "                else:\n",
    "                    transcript_data['NR']['correct'].append(max_score)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # 设置抖动范围\n",
    "        jitter_range = 0.2\n",
    "        \n",
    "        # 绘制NM转录本\n",
    "        x_nm_correct = np.random.normal(0, jitter_range, len(transcript_data['NM']['correct']))\n",
    "        x_nm_incorrect = np.random.normal(0, jitter_range, len(transcript_data['NM']['incorrect']))\n",
    "        plt.scatter(x_nm_correct, transcript_data['NM']['correct'], \n",
    "                   c='blue', alpha=0.5, label='NM Correct', s=1)\n",
    "        plt.scatter(x_nm_incorrect, transcript_data['NM']['incorrect'], \n",
    "                   c='red', alpha=0.5, label='NM Incorrect', s=1)\n",
    "        \n",
    "        # 绘制NR转录本\n",
    "        x_nr_correct = np.random.normal(1, jitter_range, len(transcript_data['NR']['correct']))\n",
    "        x_nr_incorrect = np.random.normal(1, jitter_range, len(transcript_data['NR']['incorrect']))\n",
    "        plt.scatter(x_nr_correct, transcript_data['NR']['correct'], \n",
    "                   c='blue', alpha=0.5, s=1)\n",
    "        plt.scatter(x_nr_incorrect, transcript_data['NR']['incorrect'], \n",
    "                   c='red', alpha=0.5, s=1)\n",
    "        \n",
    "        # 绘制最优阈值线\n",
    "        plt.axhline(y=best_threshold, color='g', linestyle='--', \n",
    "                   label=f'Threshold ({best_threshold:.3f})')\n",
    "        \n",
    "        plt.xticks([0, 1], ['NM', 'NR'])\n",
    "        plt.ylabel('Final Score')\n",
    "        plt.title('Transcript Score Distribution')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        stats_text = (\n",
    "            f\"NM Correct: {len(transcript_data['NM']['correct'])}\\n\"\n",
    "            f\"NM Incorrect: {len(transcript_data['NM']['incorrect'])}\\n\"\n",
    "            f\"NR Correct: {len(transcript_data['NR']['correct'])}\\n\"\n",
    "            f\"NR Incorrect: {len(transcript_data['NR']['incorrect'])}\"\n",
    "        )\n",
    "        plt.figtext(1.15, 0.5, stats_text, fontsize=10, \n",
    "                   bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.85)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'transcript_scores.png'), \n",
    "                   bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def _save_performance_data(self, results: List[PerformanceMetrics], output_file: str):\n",
    "        \"\"\"保存性能指标数据到文件\"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"Threshold\\tTP\\tFP\\tTN\\tFN\\tConstant_TN\\tConstant_FN\\tMulti_Pred_Count\\t\"\n",
    "                   \"Accuracy\\tPrecision\\tRecall\\tSpecificity\\tFPR\\tF1_Score\\n\")\n",
    "            \n",
    "            for metrics in results:\n",
    "                f.write(f\"{metrics.threshold:.3f}\\t\")\n",
    "                f.write(f\"{metrics.tp}\\t\")\n",
    "                f.write(f\"{metrics.fp}\\t\")\n",
    "                f.write(f\"{metrics.tn}\\t\")\n",
    "                f.write(f\"{metrics.fn}\\t\")\n",
    "                f.write(f\"{metrics.constant_tn}\\t\")\n",
    "                f.write(f\"{metrics.constant_fn}\\t\")\n",
    "                f.write(f\"{metrics.multi_pred_count}\\t\")\n",
    "                f.write(f\"{metrics.accuracy:.3f}\\t\")\n",
    "                f.write(f\"{metrics.precision:.3f}\\t\")\n",
    "                f.write(f\"{metrics.recall:.3f}\\t\")\n",
    "                f.write(f\"{metrics.specificity:.3f}\\t\")\n",
    "                f.write(f\"{metrics.fpr:.3f}\\t\")\n",
    "                f.write(f\"{metrics.f1_score:.3f}\\n\")\n",
    "\n",
    "    def find_optimal_threshold(self, \n",
    "                             start: float = 0.0, \n",
    "                             end: float = 1.0, \n",
    "                             step: float = 0.01) -> Dict:\n",
    "        \"\"\"寻找最优阈值，同时计算转录本层面和ORF层面的性能\"\"\"\n",
    "        thresholds = np.arange(start, end + step, step)\n",
    "        \n",
    "        transcript_results = []\n",
    "        orf_results = []\n",
    "        best_transcript_metrics = None\n",
    "        best_orf_metrics = None\n",
    "        best_transcript_f1 = -1\n",
    "        best_orf_f1 = -1\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            # 转录本层面评估\n",
    "            transcript_metrics = self.evaluate_transcript_level(threshold)\n",
    "            transcript_results.append(transcript_metrics)\n",
    "            if transcript_metrics.f1_score > best_transcript_f1:\n",
    "                best_transcript_f1 = transcript_metrics.f1_score\n",
    "                best_transcript_metrics = transcript_metrics\n",
    "            \n",
    "            # ORF层面评估\n",
    "            orf_metrics = self.evaluate_orf_level(threshold)\n",
    "            orf_results.append(orf_metrics)\n",
    "            if orf_metrics.f1_score > best_orf_f1:\n",
    "                best_orf_f1 = orf_metrics.f1_score\n",
    "                best_orf_metrics = orf_metrics\n",
    "        \n",
    "        # 保存性能指标数据\n",
    "        self._save_performance_data(transcript_results, \n",
    "                                  os.path.join(self.output_dir, \"transcript_performance.txt\"))\n",
    "        self._save_performance_data(orf_results, \n",
    "                                  os.path.join(self.output_dir, \"orf_performance.txt\"))\n",
    "        \n",
    "        # 绘制性能曲线\n",
    "        self._plot_performance_curves(transcript_results, \"transcript\")\n",
    "        self._plot_performance_curves(orf_results, \"orf\")\n",
    "        self._plot_dual_roc_curves(transcript_results, orf_results)\n",
    "        self._plot_transcript_scores(transcript_results)\n",
    "        \n",
    "        return {\n",
    "            'transcript': {\n",
    "                'threshold': best_transcript_metrics.threshold,\n",
    "                'metrics': best_transcript_metrics\n",
    "            },\n",
    "            'orf': {\n",
    "                'threshold': best_orf_metrics.threshold,\n",
    "                'metrics': best_orf_metrics\n",
    "            }\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    input_file = 'TRANSAID_Embedding_batch4_ALL_tis_tts_pairs.csv'\n",
    "    file_dir = '/home/jovyan/work/insilico_translation/embedding_type3_maxlen9995_ratio80_NM_NR/TTSTIS_selection'\n",
    "    \n",
    "    # 创建优化器\n",
    "    optimizer = ThresholdOptimizer(input_file, file_dir)\n",
    "    \n",
    "    # 寻找最优阈值并获取两种层面的结果\n",
    "    results = optimizer.find_optimal_threshold()\n",
    "    \n",
    "    # 打印转录本层面的结果\n",
    "    print(\"\\nTranscript Level Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    metrics = results['transcript']['metrics']\n",
    "    print(f\"Best Threshold: {results['transcript']['threshold']:.3f}\")\n",
    "    print(f\"Accuracy: {metrics.accuracy:.3f}\")\n",
    "    print(f\"Precision: {metrics.precision:.3f}\")\n",
    "    print(f\"Recall: {metrics.recall:.3f}\")\n",
    "    print(f\"F1 Score: {metrics.f1_score:.3f}\")\n",
    "    print(f\"\\nDetailed Counts:\")\n",
    "    print(f\"True Positives: {metrics.tp}\")\n",
    "    print(f\"False Positives: {metrics.fp}\")\n",
    "    print(f\"True Negatives: {metrics.tn}\")\n",
    "    print(f\"False Negatives: {metrics.fn}\")\n",
    "    print(f\"Constant True Negatives: {metrics.constant_tn}\")\n",
    "    print(f\"Constant False Negatives: {metrics.constant_fn}\")\n",
    "    print(f\"\\nTranscripts with Multiple Predictions: {metrics.multi_pred_count}\")\n",
    "    \n",
    "    # 打印ORF层面的结果\n",
    "    print(\"\\nORF Level Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    metrics = results['orf']['metrics']\n",
    "    print(f\"Best Threshold: {results['orf']['threshold']:.3f}\")\n",
    "    print(f\"Accuracy: {metrics.accuracy:.3f}\")\n",
    "    print(f\"Precision: {metrics.precision:.3f}\")\n",
    "    print(f\"Recall: {metrics.recall:.3f}\")\n",
    "    print(f\"F1 Score: {metrics.f1_score:.3f}\")\n",
    "    print(f\"\\nDetailed Counts:\")\n",
    "    print(f\"True Positives: {metrics.tp}\")\n",
    "    print(f\"False Positives: {metrics.fp}\")\n",
    "    print(f\"True Negatives: {metrics.tn}\")\n",
    "    print(f\"False Negatives: {metrics.fn}\")\n",
    "    print(f\"Constant True Negatives: {metrics.constant_tn}\")\n",
    "    print(f\"Constant False Negatives: {metrics.constant_fn}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729e3bf-3bee-459e-9635-00629eb11105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
