{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "630ab4bd-2c42-4969-85a4-33eeb18008e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation and Statistics:\n",
      "==================================================\n",
      "\n",
      "1. 原始数据统计:\n",
      "总行数: 18200\n",
      "包含NM_的行数: 13493\n",
      "包含NR_的行数: 4704\n",
      "\n",
      "2. 唯一转录本统计:\n",
      "唯一NM_转录本数: 13415\n",
      "唯一NR_转录本数: 4616\n",
      "\n",
      "3. 缺失值统计:\n",
      "transcript_id        0\n",
      "tis_position      3515\n",
      "tts_position      3515\n",
      "tis_sequence      3515\n",
      "tts_sequence      3515\n",
      "tis_prob_score    3515\n",
      "tts_prob_score    3515\n",
      "kozak_score       3515\n",
      "cai_score         3515\n",
      "gc_score          3515\n",
      "cds_length        3515\n",
      "final_score       3515\n",
      "filter_status        0\n",
      "true_tis          4867\n",
      "true_tts          4867\n",
      "dtype: int64\n",
      "\n",
      "4. final_score值分布:\n",
      "count                  14685\n",
      "unique                 14645\n",
      "top       0.1433264726397471\n",
      "freq                       4\n",
      "Name: final_score, dtype: object\n",
      "\n",
      "5. 每个转录本的预测数量分布:\n",
      "1    17867\n",
      "2      162\n",
      "3        3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing NaN values:\n",
      "Total transcripts with all NaN scores: 3516\n",
      "NM transcripts: 163\n",
      "NR transcripts: 3352\n",
      "\n",
      "Optimal Threshold Results:\n",
      "==================================================\n",
      "Best Threshold: 0.520\n",
      "Accuracy: 0.919\n",
      "Precision: 0.925\n",
      "Recall: 0.967\n",
      "Specificity: 0.787\n",
      "F1 Score: 0.946\n",
      "\n",
      "Detailed Counts:\n",
      "True Positives: 12738\n",
      "False Positives: 1038\n",
      "True Negatives: 3827\n",
      "False Negatives: 429\n",
      "\n",
      "Transcripts with Multiple Predictions: 164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    \"\"\"性能指标数据类\"\"\"\n",
    "    threshold: float\n",
    "    tp: int  # 真阳性\n",
    "    fp: int  # 假阳性\n",
    "    tn: int  # 真阴性\n",
    "    fn: int  # 假阴性\n",
    "    multi_pred_count: int  # 具有多个预测结果的转录本数量\n",
    "    constant_fn: int  # 由于NaN导致的恒定假阴性数量\n",
    "    constant_tn: int  # 由于NaN导致的恒定真阴性数量\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        \"\"\"计算准确率\"\"\"\n",
    "        total = self.tp + self.fp + self.tn + self.fn + self.constant_tn + self.constant_fn\n",
    "        return (self.tp + self.tn + self.constant_tn) / total if total > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def precision(self) -> float:\n",
    "        \"\"\"计算精确率\"\"\"\n",
    "        denominator = self.tp + self.fp\n",
    "        return self.tp / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def recall(self) -> float:\n",
    "        \"\"\"计算召回率\"\"\"\n",
    "        denominator = self.tp + self.fn + self.constant_fn\n",
    "        return self.tp / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def specificity(self) -> float:\n",
    "        \"\"\"计算特异性（真阴性率）\"\"\"\n",
    "        denominator = self.tn + self.fp + self.constant_tn\n",
    "        return (self.tn + self.constant_tn) / denominator if denominator > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def fpr(self) -> float:\n",
    "        \"\"\"计算假阳性率\"\"\"\n",
    "        return 1 - self.specificity\n",
    "    \n",
    "    @property\n",
    "    def f1_score(self) -> float:\n",
    "        \"\"\"计算F1分数\"\"\"\n",
    "        prec = self.precision\n",
    "        rec = self.recall\n",
    "        denominator = prec + rec\n",
    "        return 2 * (prec * rec) / denominator if denominator > 0 else 0\n",
    "\n",
    "class ThresholdOptimizer:\n",
    "    \"\"\"阈值优化器类\"\"\"\n",
    "    \n",
    "    def __init__(self, data_file: str, file_dir: str):\n",
    "        \"\"\"\n",
    "        初始化阈值优化器\n",
    "        \n",
    "        Args:\n",
    "            data_file: 包含预测结果的CSV文件名\n",
    "            file_dir: 文件目录路径\n",
    "        \"\"\"\n",
    "        self.file_dir = file_dir\n",
    "        self.data_file = os.path.join(file_dir, data_file)\n",
    "        self.df = pd.read_csv(self.data_file)\n",
    "        \n",
    "        # 数据验证和统计\n",
    "        self._validate_and_print_stats()\n",
    "        \n",
    "        # 转换final_score为数值类型并处理NaN值\n",
    "        self._process_final_scores()\n",
    "        \n",
    "        # 按transcript_id分组，获取每个转录本的所有预测\n",
    "        self.grouped_predictions = self.df.groupby('transcript_id')\n",
    "    \n",
    "    def _process_final_scores(self):\n",
    "        \"\"\"转换final_score为数值类型，并为NaN值分配随机值\"\"\"\n",
    "        # 将final_score转换为数值类型\n",
    "        self.df['final_score'] = pd.to_numeric(self.df['final_score'], errors='coerce')\n",
    "        \n",
    "        # 统计NaN值的分布情况\n",
    "        nan_transcripts = self.df.groupby('transcript_id')['final_score'].apply(lambda x: x.isna().all())\n",
    "        nan_transcripts = nan_transcripts[nan_transcripts]\n",
    "        \n",
    "        print(\"\\nProcessing NaN values:\")\n",
    "        print(f\"Total transcripts with all NaN scores: {len(nan_transcripts)}\")\n",
    "        print(f\"NM transcripts: {sum(i.startswith('NM_') for i in nan_transcripts.index)}\")\n",
    "        print(f\"NR transcripts: {sum(i.startswith('NR_') for i in nan_transcripts.index)}\")\n",
    "        \n",
    "        # 为每个全是NaN的转录本分配随机值\n",
    "        np.random.seed(42)  # 设置随机种子确保可重复性\n",
    "        for transcript_id in nan_transcripts.index:\n",
    "            # 为该转录本的所有行分配相同的随机值\n",
    "            random_score = np.random.uniform(0, 0.1)\n",
    "            self.df.loc[self.df['transcript_id'] == transcript_id, 'final_score'] = random_score\n",
    "\n",
    "    def _plot_transcript_scores(self, results: List[PerformanceMetrics]):\n",
    "        \"\"\"\n",
    "        绘制转录本得分的散点图，区分NM和NR转录本，并用不同颜色标识预测正确和错误的案例。\n",
    "        \"\"\"\n",
    "        # 收集数据点\n",
    "        transcript_data = {\n",
    "            'NM': {'correct': [], 'incorrect': []},\n",
    "            'NR': {'correct': [], 'incorrect': []}\n",
    "        }\n",
    "        \n",
    "        # 使用最优阈值的结果\n",
    "        best_threshold = max(results, key=lambda x: x.f1_score).threshold\n",
    "        \n",
    "        for transcript_id, group in self.grouped_predictions:\n",
    "            max_score = group['final_score'].max()\n",
    "            is_nm = transcript_id.startswith('NM_')\n",
    "            \n",
    "            if is_nm:\n",
    "                has_match = False\n",
    "                if max_score > best_threshold:\n",
    "                    for _, row in group.iterrows():\n",
    "                        if (pd.notna(row['true_tis']) and \n",
    "                            pd.notna(row['true_tts']) and \n",
    "                            row['tis_position'] == row['true_tis'] and \n",
    "                            row['tts_position'] == row['true_tts']):\n",
    "                            has_match = True\n",
    "                            break\n",
    "                    if has_match:\n",
    "                        transcript_data['NM']['correct'].append(max_score)\n",
    "                    else:\n",
    "                        transcript_data['NM']['incorrect'].append(max_score)\n",
    "                else:\n",
    "                    transcript_data['NM']['incorrect'].append(max_score)\n",
    "            else:\n",
    "                if max_score > best_threshold:\n",
    "                    transcript_data['NR']['incorrect'].append(max_score)\n",
    "                else:\n",
    "                    transcript_data['NR']['correct'].append(max_score)\n",
    "        \n",
    "        # 创建散点图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # 设置抖动范围\n",
    "        jitter_range = 0.2\n",
    "        \n",
    "        # 为NM转录本绘制点\n",
    "        x_nm_correct = np.random.normal(0, jitter_range, len(transcript_data['NM']['correct']))\n",
    "        x_nm_incorrect = np.random.normal(0, jitter_range, len(transcript_data['NM']['incorrect']))\n",
    "        plt.scatter(x_nm_correct, transcript_data['NM']['correct'], \n",
    "                c='blue', alpha=0.5, label='NM Correct', s=1)\n",
    "        plt.scatter(x_nm_incorrect, transcript_data['NM']['incorrect'], \n",
    "                c='red', alpha=0.5, label='NM Incorrect',s=1)\n",
    "        \n",
    "        # 为NR转录本绘制点\n",
    "        x_nr_correct = np.random.normal(1, jitter_range, len(transcript_data['NR']['correct']))\n",
    "        x_nr_incorrect = np.random.normal(1, jitter_range, len(transcript_data['NR']['incorrect']))\n",
    "        plt.scatter(x_nr_correct, transcript_data['NR']['correct'], \n",
    "                c='blue', alpha=0.5, s=1)\n",
    "        plt.scatter(x_nr_incorrect, transcript_data['NR']['incorrect'], \n",
    "                c='red', alpha=0.5, s=1)\n",
    "        \n",
    "        # 绘制最优阈值线\n",
    "        plt.axhline(y=best_threshold, color='g', linestyle='--', \n",
    "                    label=f'Threshold ({best_threshold:.3f})')\n",
    "        \n",
    "        # 设置图表属性\n",
    "        plt.xticks([0, 1], ['NM', 'NR'])\n",
    "        plt.ylabel('Final Score')\n",
    "        plt.title('Transcript Score Distribution')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # 添加统计信息\n",
    "        stats_text = (\n",
    "            f\"NM Correct: {len(transcript_data['NM']['correct'])}\\n\"\n",
    "            f\"NM Incorrect: {len(transcript_data['NM']['incorrect'])}\\n\"\n",
    "            f\"NR Correct: {len(transcript_data['NR']['correct'])}\\n\"\n",
    "            f\"NR Incorrect: {len(transcript_data['NR']['incorrect'])}\"\n",
    "        )\n",
    "        plt.figtext(1.15, 0.5, stats_text, fontsize=10, \n",
    "                    bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # 调整布局以适应图例和统计信息\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.85)\n",
    "        \n",
    "        # 保存图表\n",
    "        plt.savefig(os.path.join(self.file_dir, 'transcript_scores.png'), \n",
    "                    bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate_threshold(self, threshold: float) -> PerformanceMetrics:\n",
    "        \"\"\"评估特定阈值的性能\"\"\"\n",
    "        tp = fp = tn = fn = 0\n",
    "        multi_pred_count = 0\n",
    "        \n",
    "        # 使用集合来跟踪已处理的转录本\n",
    "        processed_transcripts = set()\n",
    "        \n",
    "        for transcript_id, group in self.grouped_predictions:\n",
    "            # 确保每个转录本只处理一次\n",
    "            if transcript_id in processed_transcripts:\n",
    "                continue\n",
    "                \n",
    "            processed_transcripts.add(transcript_id)\n",
    "            is_nm = transcript_id.startswith('NM_')\n",
    "            max_score = group['final_score'].max()\n",
    "            \n",
    "            # 统计多预测结果的转录本\n",
    "            if len(group) > 1 and group['filter_status'].eq('passed').any():\n",
    "                multi_pred_count += 1\n",
    "            \n",
    "            if max_score > threshold:\n",
    "                if is_nm:\n",
    "                    has_match = False\n",
    "                    for _, row in group.iterrows():\n",
    "                        if (pd.notna(row['true_tis']) and \n",
    "                            pd.notna(row['true_tts']) and \n",
    "                            row['tis_position'] == row['true_tis'] and \n",
    "                            row['tts_position'] == row['true_tts']):\n",
    "                            has_match = True\n",
    "                            break\n",
    "                    if has_match:\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                if is_nm:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "        \n",
    "        # 验证总数\n",
    "        total_counted = tp + fp + tn + fn\n",
    "        expected_total = len(self.grouped_predictions)\n",
    "        if total_counted != expected_total:\n",
    "            print(f\"Warning: Count mismatch. Counted: {total_counted}, Expected: {expected_total}\")\n",
    "        \n",
    "        return PerformanceMetrics(\n",
    "            threshold=threshold,\n",
    "            tp=tp,\n",
    "            fp=fp,\n",
    "            tn=tn,\n",
    "            fn=fn,\n",
    "            multi_pred_count=multi_pred_count,\n",
    "            constant_fn=0,\n",
    "            constant_tn=0\n",
    "        )\n",
    "    \n",
    "    def _save_performance_data(self, results: List[PerformanceMetrics], output_file: str):\n",
    "        \"\"\"保存性能指标数据到文件\"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            # 写入表头\n",
    "            f.write(\"Threshold\\tTP\\tFP\\tTN\\tFN\\tConstant_TN\\tConstant_FN\\tMulti_Pred_Count\\t\")\n",
    "            f.write(\"Accuracy\\tPrecision\\tRecall\\tSpecificity\\tFPR\\tF1_Score\\n\")\n",
    "            \n",
    "            # 写入数据\n",
    "            for metrics in results:\n",
    "                f.write(f\"{metrics.threshold:.3f}\\t\")\n",
    "                f.write(f\"{metrics.tp}\\t\")\n",
    "                f.write(f\"{metrics.fp}\\t\")\n",
    "                f.write(f\"{metrics.tn}\\t\")\n",
    "                f.write(f\"{metrics.fn}\\t\")\n",
    "                f.write(f\"{metrics.constant_tn}\\t\")\n",
    "                f.write(f\"{metrics.constant_fn}\\t\")\n",
    "                f.write(f\"{metrics.multi_pred_count}\\t\")\n",
    "                f.write(f\"{metrics.accuracy:.3f}\\t\")\n",
    "                f.write(f\"{metrics.precision:.3f}\\t\")\n",
    "                f.write(f\"{metrics.recall:.3f}\\t\")\n",
    "                f.write(f\"{metrics.specificity:.3f}\\t\")\n",
    "                f.write(f\"{metrics.fpr:.3f}\\t\")\n",
    "                f.write(f\"{metrics.f1_score:.3f}\\n\")\n",
    "    \n",
    "    def find_optimal_threshold(self, \n",
    "                             start: float = 0.0, \n",
    "                             end: float = 1.0, \n",
    "                             step: float = 0.01) -> Tuple[float, PerformanceMetrics]:\n",
    "        \"\"\"\n",
    "        寻找最优阈值\n",
    "        \n",
    "        Args:\n",
    "            start: 起始阈值\n",
    "            end: 结束阈值\n",
    "            step: 步长\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[float, PerformanceMetrics]: 最优阈值和对应的性能指标\n",
    "        \"\"\"\n",
    "        thresholds = np.arange(start, end + step, step)\n",
    "        best_metrics = None\n",
    "        best_f1 = -1\n",
    "        \n",
    "        # 存储所有结果用于绘图\n",
    "        results = []\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            metrics = self.evaluate_threshold(threshold)\n",
    "            results.append(metrics)\n",
    "            \n",
    "            if metrics.f1_score > best_f1:\n",
    "                best_f1 = metrics.f1_score\n",
    "                best_metrics = metrics\n",
    "        \n",
    "        # 生成输出文件名\n",
    "        output_base = self.data_file.rsplit('.', 1)[0]\n",
    "        output_file = f\"{output_base}_performence_search.txt\"\n",
    "        \n",
    "        # 保存性能指标数据\n",
    "        self._save_performance_data(results, output_file)\n",
    "        \n",
    "        # 绘制性能曲线\n",
    "        self._plot_performance_curves(results)\n",
    "        \n",
    "        # 绘制ROC曲线\n",
    "        self._plot_roc_curve(results)\n",
    "\n",
    "        # 添加新的散点图\n",
    "        self._plot_transcript_scores(results)\n",
    "        \n",
    "        return best_metrics.threshold, best_metrics\n",
    "    \n",
    "    def _plot_performance_curves(self, results: List[PerformanceMetrics]):\n",
    "        \"\"\"绘制性能曲线\"\"\"\n",
    "        thresholds = [r.threshold for r in results]\n",
    "        metrics = {\n",
    "            'Accuracy': [r.accuracy for r in results],\n",
    "            'Precision': [r.precision for r in results],\n",
    "            'Recall': [r.recall for r in results],\n",
    "            'F1 Score': [r.f1_score for r in results]\n",
    "        }\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for metric_name, values in metrics.items():\n",
    "            plt.plot(thresholds, values, label=metric_name)\n",
    "        \n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Metrics vs Threshold')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(self.file_dir, 'performance_curves.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_roc_curve(self, results: List[PerformanceMetrics]):\n",
    "        \"\"\"绘制ROC曲线\"\"\"\n",
    "        fpr = [r.fpr for r in results]\n",
    "        tpr = [r.recall for r in results]  # TPR = Recall\n",
    "        \n",
    "        # 计算AUC\n",
    "        auc = np.trapz(tpr, fpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, 'b-', label=f'ROC (AUC = {auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Random')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(self.file_dir, 'roc_curve.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    def _validate_and_print_stats(self):\n",
    "        \"\"\"验证数据并打印统计信息\"\"\"\n",
    "        print(\"\\nData Validation and Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 原始转录本计数\n",
    "        nm_transcripts = self.df['transcript_id'].str.startswith('NM_')\n",
    "        nr_transcripts = self.df['transcript_id'].str.startswith('NR_')\n",
    "        \n",
    "        print(\"\\n1. 原始数据统计:\")\n",
    "        print(f\"总行数: {len(self.df)}\")\n",
    "        print(f\"包含NM_的行数: {nm_transcripts.sum()}\")\n",
    "        print(f\"包含NR_的行数: {nr_transcripts.sum()}\")\n",
    "        \n",
    "        # 唯一转录本计数\n",
    "        unique_nm = self.df[nm_transcripts]['transcript_id'].nunique()\n",
    "        unique_nr = self.df[nr_transcripts]['transcript_id'].nunique()\n",
    "        \n",
    "        print(\"\\n2. 唯一转录本统计:\")\n",
    "        print(f\"唯一NM_转录本数: {unique_nm}\")\n",
    "        print(f\"唯一NR_转录本数: {unique_nr}\")\n",
    "        \n",
    "        # 检查缺失值\n",
    "        print(\"\\n3. 缺失值统计:\")\n",
    "        print(self.df.isnull().sum())\n",
    "        \n",
    "        # 检查final_score列的值分布\n",
    "        print(\"\\n4. final_score值分布:\")\n",
    "        print(self.df['final_score'].describe())\n",
    "        \n",
    "        # 检查是否有重复的transcript_id和position组合\n",
    "        duplicates = self.df.groupby('transcript_id').size()\n",
    "        print(\"\\n5. 每个转录本的预测数量分布:\")\n",
    "        print(duplicates.value_counts().sort_index())\n",
    "    \n",
    "    def _convert_final_score(self):\n",
    "        \"\"\"转换final_score为数值类型，并打印无法转换的值\"\"\"\n",
    "        # 在转换之前查看无法转换为数值的值\n",
    "        non_numeric = pd.to_numeric(self.df['final_score'], errors='coerce').isna()\n",
    "        if non_numeric.any():\n",
    "            print(\"\\n无法转换为数值的final_score值:\")\n",
    "            print(self.df[non_numeric][['transcript_id', 'final_score']])\n",
    "        \n",
    "        # 转换为数值类型\n",
    "        self.df['final_score'] = pd.to_numeric(self.df['final_score'], errors='coerce')\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 设置输入文件路径\n",
    "    input_file = 'TRANSAID_Embedding_batch4_ALL_tis_tts_pairs.csv'\n",
    "    file_dir = '/home/jovyan/work/insilico_translation/embedding_type3_maxlen9995_ratio80_NM_NR/TTSTIS_selection'\n",
    "    \n",
    "    # 创建优化器\n",
    "    optimizer = ThresholdOptimizer(input_file, file_dir)\n",
    "    \n",
    "    # 寻找最优阈值\n",
    "    best_threshold, best_metrics = optimizer.find_optimal_threshold()\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nOptimal Threshold Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Best Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {best_metrics.accuracy:.3f}\")\n",
    "    print(f\"Precision: {best_metrics.precision:.3f}\")\n",
    "    print(f\"Recall: {best_metrics.recall:.3f}\")\n",
    "    print(f\"Specificity: {best_metrics.specificity:.3f}\")\n",
    "    print(f\"F1 Score: {best_metrics.f1_score:.3f}\")\n",
    "    print(f\"\\nDetailed Counts:\")\n",
    "    print(f\"True Positives: {best_metrics.tp}\")\n",
    "    print(f\"False Positives: {best_metrics.fp}\")\n",
    "    print(f\"True Negatives: {best_metrics.tn}\")\n",
    "    print(f\"False Negatives: {best_metrics.fn}\")\n",
    "    print(f\"\\nTranscripts with Multiple Predictions: {best_metrics.multi_pred_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc9968-1146-4c94-b764-3cf886bae4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
